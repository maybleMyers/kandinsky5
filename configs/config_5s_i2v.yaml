metrics:
  scale_factor:
  - 1.0
  - 2.0
  - 2.0
  resolution: 512

model:
  # Path to the Lite I2V model weights
  checkpoint_path: "lite_checkpoints/kandinsky5lite_i2v_5s.safetensors"
  num_steps: 50
  guidance_weight: 5.0

  dit_params:
    # 2B Lite model architecture parameters
    in_visual_dim: 16
    out_visual_dim: 16
    time_dim: 512                # Lite: 512 (vs Pro: 1024)
    patch_size:
    - 1
    - 2
    - 2
    model_dim: 1792              # Lite: 1792 (vs Pro: 4096)
    ff_dim: 7168                 # Lite: 7168 (vs Pro: 16384)
    num_text_blocks: 2           # Lite: 2 (vs Pro: 4)
    num_visual_blocks: 32        # Lite: 32 (vs Pro: 60)
    axes_dims:
    - 16                         # Lite: 16 (vs Pro: 32)
    - 24                         # Lite: 24 (vs Pro: 48)
    - 24                         # Lite: 24 (vs Pro: 48)
    visual_cond: true
    in_text_dim: 3584
    in_text_dim2: 768
    attention_engine: "auto"     # Can be overridden via CLI: sdpa, flash_attention_2, flash_attention_3, sage

  # Attention configuration (commented out to allow CLI override)
  # Uncomment to use default flash attention, or use CLI args for flexibility
  # attention:
  #   type: flash
  #   causal: false
  #   local: false
  #   glob: false
  #   window: 3

  # VAE configuration - using same paths as Pro model
  vae:
    checkpoint_path: "Kandinsky-5.0-I2V-Pro-sft-5s-Diffusers/vae"
    name: "hunyuan"

  # Text embedder configuration - using same paths as Pro model
  text_embedder:
    qwen:
      emb_size: 3584
      checkpoint_path: "Kandinsky-5.0-I2V-Pro-sft-5s-Diffusers/text_encoder"
      processor_path: "Kandinsky-5.0-I2V-Pro-sft-5s-Diffusers/tokenizer"
      max_length: 256
    clip:
      checkpoint_path: "Kandinsky-5.0-I2V-Pro-sft-5s-Diffusers/text_encoder_2"
      tokenizer_path: "Kandinsky-5.0-I2V-Pro-sft-5s-Diffusers/tokenizer_2"
      emb_size: 768
      max_length: 77

# Block swapping configuration
# Lite model has 32 blocks, so can fit more in memory than Pro (60 blocks)
block_swap:
  enabled: false                # Disabled by default for Lite model - enable via CLI if needed
  blocks_in_memory: 32          # Can keep all 32 blocks in memory on 24GB+ VRAM
                                # Adjust based on available VRAM:
                                # - 24GB+: 32 blocks (all blocks, no swapping needed)
                                # - 16GB: 20-24 blocks
                                # - 12GB: 12-16 blocks

# MagCache configuration for Lite model (optional acceleration)
magcache:
  mag_ratios: [0.90524, 0.89864, 0.95225, 0.95382, 1.04828, 1.04658, 1.07989, 1.07921, 1.04345, 1.04345, 1.03547, 1.03589, 1.03715, 1.03745, 1.02909, 1.02907, 1.03391, 1.03416, 1.02366, 1.02392, 1.02359, 1.02415, 1.02256, 1.02289, 1.02447, 1.02502, 1.01824, 1.01857, 1.02236, 1.02261, 1.01704, 1.01736, 1.01838, 1.01857, 1.01886, 1.01961, 1.01619, 1.0169, 1.01655, 1.01702, 1.01477, 1.01545, 1.01926, 1.01981, 1.01145, 1.01227, 1.01276, 1.01308, 1.01583, 1.01619, 1.01587, 1.01641, 1.01386, 1.01418, 1.01441, 1.01505, 1.01473, 1.01491, 1.01346, 1.01407, 1.01319, 1.0137, 1.01283, 1.01313, 1.01412, 1.01407, 1.01222, 1.0127, 1.0131, 1.01315, 1.01398, 1.0143, 1.01483, 1.01498, 1.01158, 1.01176, 1.01342, 1.01365, 1.00893, 1.0095, 1.01223, 1.01237, 1.01005, 1.01045, 1.00694, 1.00679, 1.00691, 1.00742, 0.99846, 0.99916, 0.98563, 0.98549, 0.97116, 0.97145, 0.93116, 0.93069, 0.83437, 0.83375]
